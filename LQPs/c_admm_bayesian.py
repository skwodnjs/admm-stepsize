import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm
from sklearn.gaussian_process import GaussianProcessRegressor
from warnings import catch_warnings, simplefilter

from a_admm_lqp import generate_random_param_of_LQP, admm_LQP, optimal_theta

# ì„¤ì •
# seed = 42     # 21758, 25465
seed = np.random.randint(0, 100000)
np.random.seed(seed)
print(f"seed: {seed}")

param = generate_random_param_of_LQP(m=3, n=5)
max_iter = 1000

theta_max = 30

# ëª©ì  í•¨ìˆ˜
def objective(theta):
    _, _, iter_count, _ = admm_LQP(param=param, theta=theta, max_iter=max_iter)
    if iter_count is not None:
        return -iter_count

# GP ì˜ˆì¸¡ í•¨ìˆ˜
def surrogate(model, X):
    with catch_warnings():
        simplefilter("ignore")
        return model.predict(X, return_std=True)

# Acquisition Function (Probability of Improvement)
# PI
# def acquisition(X, Xsamples, model):
#     yhat, _ = surrogate(model, X)
#     best = max(yhat)
#     mu, std = surrogate(model, Xsamples)
#     probs = norm.cdf((mu - best) / (std + 1e-9))
#     return probs
# EI
def acquisition(X, Xsamples, model):
    yhat, _ = surrogate(model, X)
    best = max(yhat)
    mu, std = surrogate(model, Xsamples)
    mu = mu.flatten()
    std = std.flatten()
    imp = mu - best
    Z = imp / (std + 1e-9)
    ei = imp * norm.cdf(Z) + std * norm.pdf(Z)
    return ei

# Acquisition ìµœì í™” (nê°œ ëœë¤í•œ ì§€ì  ì¤‘ ë‹¤ìŒ íƒìƒ‰ ì§€ì  ê²°ì •)
def opt_acquisition(X, model, n=50):
    Xsamples = np.random.random(n) * theta_max + 0.1
    Xsamples = Xsamples.reshape(-1, 1)
    scores = acquisition(X, Xsamples, model)
    ix = np.argmax(scores)
    return Xsamples[ix, 0]

# surrogate ì‹œê°í™”
def plot(X, y, model):
    plt.scatter(X, y, label="observed")
    Xsamples = np.arange(0.1, theta_max, 0.05).reshape(-1, 1)
    ysamples, _ = surrogate(model, Xsamples)
    plt.plot(Xsamples, ysamples, label="surrogate")
    plt.xlabel("theta")
    plt.ylabel("-iteration count (objective)")
    plt.title("Surrogate model of ADMM iteration")
    plt.grid(True)
    plt.legend()
    plt.show()

# ì´ˆê¸° ìƒ˜í”Œ ìˆ˜ì§‘
X_raw = np.random.random(50) * theta_max + 0.1
# X_raw = np.random.random(30) * theta_max + 0.1
X, y = [], []
for x in X_raw:
    val = objective(x)
    if val is not None:
        X.append([x])
        y.append([val])
X = np.asarray(X)
y = np.asarray(y)

# surrogate ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸° í•™ìŠµ
model = GaussianProcessRegressor()
model.fit(X, y)
plot(X, y, model)

# ìµœì í™” ë£¨í”„
for i in range(50):
    x = opt_acquisition(X, model)
    actual = objective(x)
    if actual is None:
        print(f"> Iter {i+1:02d}: theta={x:.4f}, skipped (diverged or max_iter reached)")   # íƒìƒ‰í•œ ì§€ì ì—ì„œ ADMMì´ MAX_ITERì— ë„ë‹¬í•¨
        continue
    est, _ = surrogate(model, [[x]])
    print(f"> Iter {i+1:02d}: theta={x:.4f}, predicted={est[0]:.3f}, actual={actual:.3f}")  # íƒìƒ‰ ê²°ê³¼: ì˜ˆì¸¡ê°’ & ì‹¤ì œê°’
    X = np.vstack((X, [[x]]))
    y = np.vstack((y, [[actual]]))
    model.fit(X, y)     # ì‹¤ì œ ê°’ìœ¼ë¡œ GP ëª¨ë¸ í•™ìŠµ

ix = np.argmax(y)
theta_bayesian = X[ix][0]
theta_opt, _ = optimal_theta(param=param)

# ADMM ì‹¤í–‰ (Bayesian ê²°ê³¼)
(u_bayes, _), obj_bayes, iter_bayes, time_bayes = admm_LQP(param=param, theta=theta_bayesian)

# ADMM ì‹¤í–‰ (Gradient Descent ê²°ê³¼)
(u_gd, _), obj_gd, iter_gd, time_gd = admm_LQP(param=param, theta=theta_opt)

print("\nğŸ“Œ ADMM Î¸ íƒìƒ‰ ê²°ê³¼ ìš”ì•½")
print(f"â–¶ Bayesian Optimization Î¸ \t: {theta_bayesian:.6f}")
print(f"  â†ª ë°˜ë³µ íšŸìˆ˜              \t: {iter_bayes}")
print(f"  â†ª u                     \t: {u_bayes}")
print(f"  â†ª objective value       \t: {obj_bayes:.9f}")
print(f"  â†ª ìˆ˜í–‰ ì‹œê°„              \t: {time_bayes:.6f} sec")
print()
print(f"â–¶ Gradient Descent Î¸*     \t: {theta_opt:.6f}")
print(f"  â†ª ë°˜ë³µ íšŸìˆ˜              \t: {iter_gd}")
print(f"  â†ª u                     \t: {u_gd}")
print(f"  â†ª objective value       \t: {obj_gd:.9f}")
print(f"  â†ª ìˆ˜í–‰ ì‹œê°„              \t: {time_gd:.6f} sec")

# ìµœì¢… ê²°ê³¼ ì‹œê°í™”
plot(X, y, model)
